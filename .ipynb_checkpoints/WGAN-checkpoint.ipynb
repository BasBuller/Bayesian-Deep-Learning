{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from data_train_test_funcs import mnist_dataloaders, train, sample_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = True\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "epochs = 200\n",
    "critic_upd_steps = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = mnist_dataloaders(batch_size=batch_size, num_workers=num_workers, pin_memory=gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClampWeights:\n",
    "    r\"\"\"Simple clipping functionality that will clip weights of module if it has such a tensor.\"\"\"\n",
    "    def __init__(self, low, high):\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "\n",
    "    def __call__(self, module):\n",
    "        if hasattr(module, \"weight\"):\n",
    "            module.weight.data.clamp_(self.low, self.high)\n",
    "            \n",
    "            \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, l_sizes, activation=\"relu\", noise_prior=\"uniform\"):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.l_sizes = [*l_sizes, 784]\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Set noise prior\n",
    "        if noise_prior == \"uniform\":\n",
    "            self.noise_prior = torch.distributions.Uniform(0, 1)\n",
    "        elif noise_prior == \"normal\":\n",
    "            self.noise_prior = torch.distributions.Normal(0, 1)\n",
    "        else:\n",
    "            raise ValueError(\"No valid prior distribution type selected\")\n",
    "        \n",
    "        # Generator activation function generator\n",
    "        if activation == \"relu\":\n",
    "            act_fun = nn.ReLU\n",
    "        elif activation == \"leakyrelu\":\n",
    "            act_fun = nn.LeakyReLU\n",
    "        elif activation == \"sigmoid\":\n",
    "            act_fun == nn.Sigmoid\n",
    "        else:\n",
    "            raise ValueError(\"No valid activation function selected\")\n",
    "        \n",
    "        # Generator\n",
    "        gen_layers = []\n",
    "        for idx in range(len(self.l_sizes[:-1])):\n",
    "            gen_layers.append((f\"fc{idx}\", nn.Linear(self.l_sizes[idx], self.l_sizes[idx+1])))\n",
    "            if idx != (len(self.l_sizes) - 2):\n",
    "                gen_layers.append((f\"{activation}{idx}\", act_fun()))\n",
    "            else:  # Sigmoid for final layer\n",
    "                gen_layers.append((f\"sigmoid{idx}\", nn.Tanh()))\n",
    "            \n",
    "        gen_dict = OrderedDict(gen_layers)\n",
    "        self.generator = nn.Sequential(gen_dict)\n",
    "        print(self.generator)\n",
    "        \n",
    "    def noise(self, batch_size):\n",
    "        device = next(self.parameters()).device\n",
    "        noise = self.noise_prior.rsample((batch_size, self.l_sizes[0]))\n",
    "        return noise\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.generator(x)\n",
    "        return y\n",
    "        \n",
    "        \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, l_sizes, activation=\"relu\"):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        self.l_sizes = [784, *l_sizes, 1]\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Discriminator activation function generator\n",
    "        if activation == \"relu\":\n",
    "            act_fun = nn.ReLU\n",
    "        elif activation == \"leakyrelu\":\n",
    "            act_fun = nn.LeakyReLU\n",
    "        elif activation == \"sigmoid\":\n",
    "            act_fun == nn.Sigmoid\n",
    "        else:\n",
    "            raise ValueError(\"No valid activation function selected\")\n",
    "            \n",
    "        # Discriminator\n",
    "        critic_layers = []\n",
    "        for idx in range(len(self.l_sizes[:-1])):\n",
    "            critic_layers.append((f\"fc{idx}\", nn.Linear(self.l_sizes[idx], self.l_sizes[idx+1])))\n",
    "            if idx != (len(self.l_sizes) - 2):\n",
    "                critic_layers.append((f\"{activation}{idx}\", act_fun()))\n",
    "            else:  # Sigmoid for final layer\n",
    "                critic_layers.append((f\"sigmoid{idx}\", nn.Sigmoid()))\n",
    "            \n",
    "        critic_dict = OrderedDict(critic_layers)\n",
    "        self.critic = nn.Sequential(critic_dict)\n",
    "        print(self.critic)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        y = self.critic(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (fc0): Linear(in_features=32, out_features=128, bias=True)\n",
      "  (leakyrelu0): LeakyReLU(negative_slope=0.01)\n",
      "  (fc1): Linear(in_features=128, out_features=256, bias=True)\n",
      "  (leakyrelu1): LeakyReLU(negative_slope=0.01)\n",
      "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (leakyrelu2): LeakyReLU(negative_slope=0.01)\n",
      "  (fc3): Linear(in_features=512, out_features=784, bias=True)\n",
      "  (sigmoid3): Tanh()\n",
      ")\n",
      "Sequential(\n",
      "  (fc0): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (leakyrelu0): LeakyReLU(negative_slope=0.01)\n",
      "  (fc1): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (leakyrelu1): LeakyReLU(negative_slope=0.01)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (leakyrelu2): LeakyReLU(negative_slope=0.01)\n",
      "  (fc3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (sigmoid3): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Gen\n",
    "gen_layers = [32, 128, 256, 512]\n",
    "generator = Generator(gen_layers, activation=\"leakyrelu\", noise_prior=\"normal\")\n",
    "gen_optimizer = optim.RMSprop(generator.parameters(), 0.00005)\n",
    "\n",
    "# Critic\n",
    "critic = Critic([512, 256, 128], activation=\"leakyrelu\")\n",
    "critic_optimizer = optim.RMSprop(critic.parameters(), 0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(batch, b_idx):\n",
    "    \n",
    "    # generate samples\n",
    "    x = batch[0]\n",
    "    noise = generator.noise(x.shape[0]).to(x.device)\n",
    "    gen_samples = generator(noise)\n",
    "    critic_optimizer.zero_grad()\n",
    "    \n",
    "    # Get critic output for true and generated samples\n",
    "    true_crit = critic(x)\n",
    "    generated_crit = critic(gen_samples.detach())\n",
    "    \n",
    "    # Perform optimization step\n",
    "    critic_loss = - true_crit.mean() + generated_crit.mean()\n",
    "    critic_loss.backward()\n",
    "    critic_optimizer.step()\n",
    "    \n",
    "    # Clamp weights\n",
    "    for param in critic.parameters():\n",
    "        param.data.clamp_(-0.01, 0.01)\n",
    "    \n",
    "    # Generator update every N steps\n",
    "    if (b_idx % critic_upd_steps) == 0:\n",
    "        gen_optimizer.zero_grad()\n",
    "        \n",
    "        # Generate new images\n",
    "        gen_samples = generator(noise)\n",
    "        # Run generated images through critic\n",
    "        generated_crit = critic(gen_samples)\n",
    "        gen_loss = - generated_crit.mean()\n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "        \n",
    "    else:\n",
    "        gen_loss = torch.tensor(0)\n",
    "        \n",
    "    return OrderedDict([\n",
    "        (\"Critic loss\", critic_loss.item()),\n",
    "        (\"Generator loss\", gen_loss.item()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [00:36<01:33,  2.59s/it, Critic loss=6.85e-5, Generator loss=0]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7120b1b073ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ai_projects/basic_neural_networks/data_train_test_funcs.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_step, models, dataloader, epochs, gpu)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# Run forward and backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Update progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e7fe9781a9ac>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(batch, b_idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcritic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrue_crit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgenerated_crit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mcritic_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Clamp weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Torch/lib/python3.6/site-packages/torch/optim/rmsprop.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_avg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                     \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msquare_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(train_step, [generator, critic], train_loader, epochs=epochs, gpu=gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_images(generator, generator.noise(32).cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
