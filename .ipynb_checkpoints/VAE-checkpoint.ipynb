{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.distributions as distr\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_workers = 4\n",
    "\n",
    "# Transforms\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Train\n",
    "train_mnist = datasets.MNIST(\"./data\", train=True, transform=transform)\n",
    "train_loader = DataLoader(train_mnist, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "# Test\n",
    "test_mnist = datasets.MNIST(\"./data\", train=False, transform=transform)\n",
    "test_loader = DataLoader(test_mnist, shuffle=True, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, l0, l1):\n",
    "        super(Encoder, self).__init__()\n",
    "         \n",
    "        # Define layers\n",
    "        self.fc0 = nn.Linear(28*28, l0)\n",
    "        self.fc1_mu = nn.Linear(l0, l1)\n",
    "        self.fc1_sigma = nn.Linear(l0, l1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        # Hidden\n",
    "        x = self.fc0(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Latent\n",
    "        mu = self.fc1_mu(x)\n",
    "        logvar = self.fc1_sigma(x)\n",
    "        sigma = torch.exp(0.5 * logvar)\n",
    "        \n",
    "        return mu, sigma\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, l0, l1):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc0 = nn.Linear(l0, l1)\n",
    "        self.fc1 = nn.Linear(l1, 28*28)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Hidden\n",
    "        x = self.fc0(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Output\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, l0, l1):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = Encoder(l1, l0)\n",
    "        self.decoder = Decoder(l0, l1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Generate deterministic mean and std\n",
    "        z_mu, z_sigma = self.encoder(x)\n",
    "        \n",
    "        # Sample epsilon and make z stochastic\n",
    "        eps = torch.randn_like(z_sigma)\n",
    "        z = z_mu + z_sigma * epsilon\n",
    "        \n",
    "        # Perform decoding, or sample from X\n",
    "        y = self.decoder(z)\n",
    "        \n",
    "        return y, z_mu, z_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sqr(x):\n",
    "    res = torch.pow(x, 2)\n",
    "    return(res)\n",
    "\n",
    "def elbo_kld(mu, sigma):\n",
    "    kld = 0.5 * (1 + torch.log(sqr(sigma)) - sqr(mu) - sqr(sigma)).sum()\n",
    "    return kld\n",
    "\n",
    "def ELBO(mu, sigma, output, input):\n",
    "    reconstruction_error = F.binary_cross_entropy(output, input, reduction=\"sum\")\n",
    "    kld = elbo_kld(mu, sigm)\n",
    "    return reconstruction_error + kld"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(400, 20)\n",
    "optim = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "for _ in range(epochs):\n",
    "    for b_idx, batch in enumerate(train_loader):\n",
    "        x, _ = batch\n",
    "        net_x, latent_z = model(x)\n",
    "        \n",
    "        loss = ELBO()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
